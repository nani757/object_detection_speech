{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_objects():\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Failed to open video capture device.\")\n",
    "        exit()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Failed to capture frame.\")\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = model(frame)\n",
    "\n",
    "        # Print the detected object classes and confidence scores\n",
    "        for i, (class_id, score, bbox) in enumerate(zip(results.pred[0][:, 5], results.pred[0][:, 4], results.pred[0][:, :4])):\n",
    "            class_name = model.names[int(class_id)]\n",
    "            print(f\"Detected object: {class_name}, score={score}\")\n",
    "\n",
    "            # Draw the box and label on the frame\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"{class_name} {score:.2f}\", (int(x1), int(y1 - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow('Object Detection', frame)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "\n",
    "def detect_objects(source):\n",
    "    # Load the YOLOv5 model\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "    # Open the video capture device\n",
    "    cap = cv2.VideoCapture(source)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Failed to open video capture device.\")\n",
    "        exit()\n",
    "\n",
    "    while True:\n",
    "        # Read the next frame from the video capture device\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Failed to capture frame.\")\n",
    "            break\n",
    "\n",
    "        # Convert the frame from BGR to RGB\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Perform object detection on the frame\n",
    "        results = model(frame)\n",
    "\n",
    "        # Print the detected object classes and confidence scores to the terminal\n",
    "        for i, (class_id, score, bbox) in enumerate(zip(results.pred[0][:, 5], results.pred[0][:, 4], results.pred[0][:, :4])):\n",
    "            class_name = model.names[int(class_id)]\n",
    "            print(f\"Detected object: {class_name}, score={score}\")\n",
    "\n",
    "            # Draw the bounding box and label on the frame\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"{class_name} {score:.2f}\", (int(x1), int(y1 - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Show the resulting frame\n",
    "        cv2.imshow('Object Detection', frame)\n",
    "\n",
    "        # Wait for key press or exit\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Clean up\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/balgopal/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2023-4-1 Python-3.10.6 torch-2.0.0+cu117 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Failed to open video capture device.\")\n",
    "    exit()\n",
    "\n",
    "def detect_objects():\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Failed to capture frame.\")\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = model(frame)\n",
    "\n",
    "        # Print the detected object classes\n",
    "        for i, (class_id, score, bbox) in enumerate(zip(results.pred[0][:, 5], results.pred[0][:, 4], results.pred[0][:, :4])):\n",
    "            class_name = model.names[int(class_id)]\n",
    "            print(f\"Detected object: {class_name}\")\n",
    "\n",
    "        cv2.imshow('Object Detection', frame)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected object: person\n",
      "Detected object: person\n",
      "Detected object: person\n",
      "Detected object: tie\n",
      "Detected object: person\n",
      "Detected object: tie\n",
      "Detected object: person\n",
      "Detected object: tie\n",
      "Detected object: person\n",
      "Detected object: tie\n",
      "Detected object: person\n",
      "Detected object: tie\n",
      "Detected object: person\n",
      "Detected object: tie\n",
      "Detected object: person\n",
      "Detected object: tie\n",
      "Detected object: person\n",
      "Detected object: tie\n",
      "Detected object: person\n",
      "Detected object: person\n",
      "Detected object: tie\n",
      "Detected object: person\n",
      "Detected object: person\n",
      "Detected object: person\n",
      "Detected object: tie\n",
      "Detected object: tie\n",
      "Detected object: person\n",
      "Detected object: person\n",
      "Detected object: tie\n",
      "Detected object: person\n",
      "Detected object: tie\n",
      "Detected object: person\n",
      "Detected object: tie\n",
      "Detected object: person\n",
      "Detected object: person\n",
      "Detected object: person\n"
     ]
    }
   ],
   "source": [
    "detect_objects()\n",
    "# detect_objects(0)  # capture video from the default camera device\n",
    "# detect_objects('file.mp4')  # capture video from a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "import threading\n",
    "\n",
    "def text_to_speech(text):\n",
    "    class SpeechEngineThread(threading.Thread):\n",
    "        def __init__(self, text):\n",
    "            threading.Thread.__init__(self)\n",
    "            self.text = text\n",
    "\n",
    "        def run(self):\n",
    "            engine = pyttsx3.init()\n",
    "            engine.say(self.text)\n",
    "            engine.runAndWait()\n",
    "\n",
    "    speech_thread = SpeechEngineThread(text)\n",
    "    speech_thread.start()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    while True:\n",
    "        text = input(\"Detected object: \")\n",
    "        text_to_speech(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/balgopal/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2023-4-1 Python-3.10.6 torch-2.0.0+cu117 CPU\n",
      "\n",
      "Fusing layers... \n",
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected object: person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/balgopal/code/private_projects/object_decetion_speach/obj_det_speach/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected object: person\n",
      "Detected object: person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_4131/2009612397.py\", line 45, in run\n",
      "  File \"/home/balgopal/code/private_projects/object_decetion_speach/obj_det_speach/lib/python3.10/site-packages/pyttsx3/engine.py\", line 177, in runAndWait\n",
      "    raise RuntimeError('run loop already started')\n",
      "RuntimeError: run loop already started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected object: person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <bound method EspeakDriver._onSynth of <pyttsx3.drivers.espeak.EspeakDriver object at 0x7fdfd199dcf0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/balgopal/code/private_projects/object_decetion_speach/obj_det_speach/lib/python3.10/site-packages/pyttsx3/drivers/espeak.py\", line 153, in _onSynth\n",
      "    self._proxy.notify('started-word',\n",
      "AttributeError: 'EspeakDriver' object has no attribute '_proxy'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected object: person\n",
      "Detected object: toothbrush\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <bound method C3.forward of C3(\n",
      "  (cv1): Conv(\n",
      "    (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (cv2): Conv(\n",
      "    (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (cv3): Conv(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (m): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/balgopal/code/private_projects/object_decetion_speach/obj_det_speach/lib/python3.10/site-packages/pyttsx3/drivers/espeak.py\", line 171, in _onSynth\n",
      "    self._proxy.notify('finished-utterance', completed=True)\n",
      "ReferenceError: weakly-referenced object no longer exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected object: person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_4131/2009612397.py\", line 45, in run\n",
      "  File \"/home/balgopal/code/private_projects/object_decetion_speach/obj_det_speach/lib/python3.10/site-packages/pyttsx3/engine.py\", line 177, in runAndWait\n",
      "    raise RuntimeError('run loop already started')\n",
      "RuntimeError: run loop already started\n",
      "Exception in thread Thread-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_4131/2009612397.py\", line 45, in run\n",
      "  File \"/home/balgopal/code/private_projects/object_decetion_speach/obj_det_speach/lib/python3.10/site-packages/pyttsx3/engine.py\", line 177, in runAndWait\n",
      "    raise RuntimeError('run loop already started')\n",
      "RuntimeError: run loop already started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected object: person\n",
      "Detected object: toothbrush\n",
      "Detected object: person\n",
      "Detected object: toothbrush\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-17:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_4131/2009612397.py\", line 45, in run\n",
      "  File \"/home/balgopal/code/private_projects/object_decetion_speach/obj_det_speach/lib/python3.10/site-packages/pyttsx3/engine.py\", line 177, in runAndWait\n",
      "    raise RuntimeError('run loop already started')\n",
      "RuntimeError: run loop already started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected object: person\n",
      "Detected object: cell phone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <bound method autocast.__exit__ of <torch.cuda.amp.autocast_mode.autocast object at 0x7fdfd199dc30>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/balgopal/code/private_projects/object_decetion_speach/obj_det_speach/lib/python3.10/site-packages/pyttsx3/drivers/espeak.py\", line 171, in _onSynth\n",
      "    self._proxy.notify('finished-utterance', completed=True)\n",
      "ReferenceError: weakly-referenced object no longer exists\n",
      "Exception in thread Thread-18:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_4131/2009612397.py\", line 45, in run\n",
      "  File \"/home/balgopal/code/private_projects/object_decetion_speach/obj_det_speach/lib/python3.10/site-packages/pyttsx3/engine.py\", line 177, in runAndWait\n",
      "    raise RuntimeError('run loop already started')\n",
      "RuntimeError: run loop already started\n",
      "Exception in thread Thread-19:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/tmp/ipykernel_4131/2009612397.py\", line 45, in run\n",
      "  File \"/home/balgopal/code/private_projects/object_decetion_speach/obj_det_speach/lib/python3.10/site-packages/pyttsx3/engine.py\", line 177, in runAndWait\n",
      "    raise RuntimeError('run loop already started')\n",
      "RuntimeError: run loop already started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected object: person\n",
      "Detected object: toothbrush\n",
      "Detected object: person\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import pyttsx3\n",
    "import threading\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Failed to open video capture device.\")\n",
    "    exit()\n",
    "\n",
    "def detect_objects():\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Failed to capture frame.\")\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = model(frame)\n",
    "\n",
    "        # Print the detected object classes and convert them to speech\n",
    "        for i, (class_id, score, bbox) in enumerate(zip(results.pred[0][:, 5], results.pred[0][:, 4], results.pred[0][:, :4])):\n",
    "            class_name = model.names[int(class_id)]\n",
    "            print(f\"Detected object: {class_name}\")\n",
    "            text_to_speech(class_name)\n",
    "\n",
    "        cv2.imshow('Object Detection', frame)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def text_to_speech(text):\n",
    "    class SpeechEngineThread(threading.Thread):\n",
    "        def __init__(self, text):\n",
    "            threading.Thread.__init__(self)\n",
    "            self.text = text\n",
    "\n",
    "        def run(self):\n",
    "            engine = pyttsx3.init()\n",
    "            engine.say(self.text)\n",
    "            engine.runAndWait()\n",
    "\n",
    "    speech_thread = SpeechEngineThread(text)\n",
    "    speech_thread.start()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    detect_objects()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "objec_det_prj",
   "language": "python",
   "name": "objec_det_prj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
